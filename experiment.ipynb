{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 10), (1000,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,y=make_classification(n_samples=1000,n_features=10,n_classes=2,weights=[0.8,0.2])\n",
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((700, 10), (700,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=18)\n",
    "X_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'penalty': 'elasticnet',\n",
    "    'solver': 'saga',\n",
    "    'C':1.2,\n",
    "    'random_state':18,\n",
    "    'l1_ratio':0.2\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.94       233\n",
      "           1       0.84      0.69      0.75        67\n",
      "\n",
      "    accuracy                           0.90       300\n",
      "   macro avg       0.88      0.82      0.85       300\n",
      "weighted avg       0.90      0.90      0.90       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr=LogisticRegression(**params)\n",
    "lr.fit(X_train,y_train)\n",
    "y_pred=lr.predict(X_test)\n",
    "report=classification_report(y_test,y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.9142857142857143,\n",
       "  'recall': 0.9613733905579399,\n",
       "  'f1-score': 0.9372384937238494,\n",
       "  'support': 233.0},\n",
       " '1': {'precision': 0.8363636363636363,\n",
       "  'recall': 0.6865671641791045,\n",
       "  'f1-score': 0.7540983606557377,\n",
       "  'support': 67.0},\n",
       " 'accuracy': 0.9,\n",
       " 'macro avg': {'precision': 0.8753246753246753,\n",
       "  'recall': 0.8239702773685222,\n",
       "  'f1-score': 0.8456684271897935,\n",
       "  'support': 300.0},\n",
       " 'weighted avg': {'precision': 0.896883116883117,\n",
       "  'recall': 0.9,\n",
       "  'f1-score': 0.8963371973386377,\n",
       "  'support': 300.0}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_dict = classification_report(y_test, y_pred, output_dict=True)\n",
    "report_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/08 23:40:58 INFO mlflow.tracking.fluent: Experiment with name 'first experiment' does not exist. Creating a new experiment.\n",
      "2024/10/08 23:41:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlflow.models.model.ModelInfo at 0x1ff74409600>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment('first experiment')\n",
    "mlflow.set_registry_uri(uri='http://127.0.0.1:5000')\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_metrics({\n",
    "        'accuracy': report_dict['accuracy'],\n",
    "        'recall_class_0': report_dict['0']['recall'],\n",
    "        'recall_class_1': report_dict['1']['recall'],\n",
    "        'f1_score_macro': report_dict['macro avg']['f1-score']\n",
    "    })\n",
    "\n",
    "mlflow.sklearn.log_model(lr,'logistic regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
